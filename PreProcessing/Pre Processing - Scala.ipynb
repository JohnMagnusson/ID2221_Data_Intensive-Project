{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all good\n"
     ]
    }
   ],
   "source": [
    "import scala.util.matching\n",
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.spark.sql.functions.{min, max, mean, stddev, typedLit, when}\n",
    "import org.apache.spark.sql.types.{IntegerType, DoubleType}\n",
    "\n",
    "println(\"all good\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data is in the format:\n",
    "\n",
    "{\n",
    "\"conversionSymbol\": \"\",\n",
    "\"volumeto\": 6685400.72, \n",
    "\"high\": 9165.89, \n",
    "\"low\": 9144.6, \n",
    "\"time\": 1595030400, \n",
    "\"volumefrom\": 730.39, \n",
    "\"close\": 9151.68, \n",
    "\"open\": 9156.79, \n",
    "\"conversionType\": \"direct\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TradingInfo(1595466000,9540.53,9515.47,9524.38,1555.82,1.483120278E7,9538.04,\\direct\\,\\\\)\n",
      "TradingInfo(1595469600,9545.07,9512.26,9538.04,1358.04,1.293527787E7,9514.73,\\direct\\,\\\\)\n",
      "TradingInfo(1595473200,9514.84,9486.07,9514.73,1372.42,1.303854406E7,9508.16,\\direct\\,\\\\)\n",
      "All good\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defined class TradingInfo\n",
       "filename = ../Datasets/bitcoin_json.txt\n",
       "tradingInformation = MapPartitionsRDD[6] at map at <console>:40\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "createTradingInfo: (data: String)TradingInfo\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[6] at map at <console>:40"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class TradingInfo (time: Int,\n",
    "                        high: Double,\n",
    "                        low: Double,\n",
    "                        open: Double,\n",
    "                        volumefrom: Double,\n",
    "                        volumeto: Double, \n",
    "                        close: Double,\n",
    "                        conversionType: String,\n",
    "                        conversionSymbol: String                        \n",
    "                       )\n",
    "\n",
    "def createTradingInfo(data: String): TradingInfo = {\n",
    "    val s = data.split(\", \")\n",
    "    return TradingInfo(s(0).split(\": \")(1).toInt, s(1).split(\": \")(1).toDouble, s(2).split(\": \")(1).toDouble, \n",
    "                       s(3).split(\": \")(1).toDouble, s(4).split(\": \")(1).toDouble, s(5).split(\": \")(1).toDouble, \n",
    "                       s(6).split(\": \")(1).toDouble, s(7).split(\": \")(1), s(8).split(\": \")(1))\n",
    "}\n",
    "\n",
    "val filename = \"../Datasets/bitcoin_json.txt\"\n",
    "//val johnFileName = \"//home/john/ID2221-Labs/PreProcessing/\"\n",
    "val tradingInformation = sc.textFile(filename).\n",
    "            flatMap(l => l.split(\"},\")).\n",
    "            map(x => x.replace(\"[\", \"\")).\n",
    "            map(x => x.replace(\"{\", \"\")).\n",
    "            map(x => x.replace(\"\\\"\", \"\")).\n",
    "            map(createTradingInfo)\n",
    "            .cache()\n",
    "\n",
    "tradingInformation.take(3).foreach(println)\n",
    "\n",
    "println(\"All good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "All good\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df = [time: int, high: double ... 7 more fields]\n",
       "df1 = [time: int, high: double ... 8 more fields]\n",
       "ratio = 0.9\n",
       "training_size = 53851.5\n",
       "testing_size = 59825\n",
       "training_position = 1582441200\n",
       "testing_position = 1602626400\n",
       "training_set = [time: int, high: double ... 8 more fields]\n",
       "validation_set = [time: int, high: double ... 8 more fields]\n",
       "testing_set = [time: int, high: double ... 8 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[time: int, high: double ... 8 more fields]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Data Action\n",
    "\n",
    "val df = spark.createDataFrame(tradingInformation).sort(\"time\")\n",
    "val df1 = df.withColumn(\"midPrice\",($\"high\" + $\"low\")/2)\n",
    "\n",
    "// df1.show(5)\n",
    "\n",
    "val ratio: Double = 0.9\n",
    "val training_size = df1.count*ratio\n",
    "val testing_size = df1.count - 10\n",
    "\n",
    "val training_position = df1.take(training_size.toInt).last.getInt(0)\n",
    "val testing_position = df1.take(testing_size.toInt).last.getInt(0)\n",
    "\n",
    "// val df2 = df1.withColumn(\"dataset\", when(col(\"time\") <= training_position,\"training\")\n",
    "//       .when(col(\"time\") > training_position and col(\"time\") <= testing_position,\"validation\")\n",
    "//       .otherwise(\"testing\"))\n",
    "// df2.show(5)\n",
    "\n",
    "\n",
    "val training_set = df1.filter($\"time\" <= training_position).cache()\n",
    "val validation_set = df1.filter($\"time\" > training_position).filter($\"time\" <= testing_position).cache()\n",
    "val testing_set = df1.filter($\"time\" > testing_position).cache()\n",
    "\n",
    "\n",
    "// training_set.show(5)\n",
    "// validation_set.show(5)\n",
    "// testing_set.show(5)\n",
    "\n",
    "\n",
    "println(testing_set.count)\n",
    "\n",
    "println(\"All good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+------+-------+----------+--------+-------+--------------+----------------+-----------------+--------------------+--------------------+--------------------+\n",
      "|      time|   high|   low|   open|volumefrom|volumeto|  close|conversionType|conversionSymbol|         midPrice|        midPriceNorm|      volumefromNorm|        volumetoNorm|\n",
      "+----------+-------+------+-------+----------+--------+-------+--------------+----------------+-----------------+--------------------+--------------------+--------------------+\n",
      "|1388581200|  967.0|718.46|  812.9|     1.012|  889.99|  967.0|      \\direct\\|              \\\\|           842.73| 0.03430077268445006|1.203243540332955...|3.860005357360329E-7|\n",
      "|1388584800| 759.11|750.13| 750.13|     1.661| 1282.36| 759.11|      \\direct\\|              \\\\|           754.62|0.029799236920461117|1.974888854242133...|5.561766390706178E-7|\n",
      "|1388588400|1169.16|912.66|1169.16|    0.5916|  575.07|1000.26|      \\direct\\|              \\\\|          1040.91| 0.04442577958159372| 7.03398101246024E-8| 2.49415530607895E-7|\n",
      "|1388592000| 759.11|745.01| 759.11|    0.9084|  841.07| 745.01|      \\direct\\|              \\\\|           752.06|0.029668446640631223|1.080065644306775...|3.647832791284230...|\n",
      "|1388595600| 750.13|745.01| 745.01|    0.4054|  340.39| 750.13|      \\direct\\|              \\\\|747.5699999999999| 0.02943905275139833|4.820108016314032E-8|1.476316839056486...|\n",
      "+----------+-------+------+-------+----------+--------+-------+--------------+----------------+-----------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- time: integer (nullable = false)\n",
      " |-- high: double (nullable = false)\n",
      " |-- low: double (nullable = false)\n",
      " |-- open: double (nullable = false)\n",
      " |-- volumefrom: double (nullable = false)\n",
      " |-- volumeto: double (nullable = false)\n",
      " |-- close: double (nullable = false)\n",
      " |-- conversionType: string (nullable = true)\n",
      " |-- conversionSymbol: string (nullable = true)\n",
      " |-- midPrice: double (nullable = true)\n",
      " |-- midPriceNorm: double (nullable = true)\n",
      " |-- volumefromNorm: double (nullable = true)\n",
      " |-- volumetoNorm: double (nullable = true)\n",
      "\n",
      "All good\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "data_type = cleaned_data/training_set\n",
       "dataset = [time: int, high: double ... 8 more fields]\n",
       "statistics = [3506.103169300478,3871.254468896739,171.35000000000002,19744.67,3401.369493895933,55179.039868938766,0.0,8410599.9,1.172089303648103E7,2.980054803564982E7,0.0,2.30567037505E9]\n",
       "midPrice_mean = 3506.103169300478\n",
       "midPrice_std = 3871.254468896739\n",
       "midPrice_min = 171.35000000000002\n",
       "midPrice_max = 19744.67\n",
       "midPrice_range = 19573.32\n",
       "volumefrom_mean = 3401.369493895933\n",
       "volumefrom_std = 55179.039868938766\n",
       "volumefrom_min = 0.0\n",
       "volumefrom_max = 8410599.9\n",
       "volumefrom_range = 8410599.9\n",
       "volumeto_mean = 1.172089303648103E7\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "v...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.172089303648103E7"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// training_set\n",
    "// validation_set\n",
    "// testing_set\n",
    "val data_type = \"cleaned_data/training_set\"\n",
    "val dataset = training_set\n",
    "\n",
    "val statistics = dataset.agg(mean(\"midPrice\"), stddev(\"midPrice\"), min(\"midPrice\"), max(\"midPrice\"),\n",
    "                                  mean(\"volumefrom\"), stddev(\"volumefrom\"), min(\"volumefrom\"), max(\"volumefrom\"),\n",
    "                                  mean(\"volumeto\"), stddev(\"volumeto\"), min(\"volumeto\"), max(\"volumeto\")).head()\n",
    "\n",
    "val midPrice_mean = statistics.getDouble(0)\n",
    "val midPrice_std = statistics.getDouble(1)\n",
    "val midPrice_min = statistics.getDouble(2)\n",
    "val midPrice_max = statistics.getDouble(3)\n",
    "val midPrice_range = midPrice_max - midPrice_min\n",
    "\n",
    "// // VolumeFrom\n",
    "val volumefrom_mean = statistics.getDouble(4)\n",
    "val volumefrom_std = statistics.getDouble(5)\n",
    "val volumefrom_min = statistics.getDouble(6)\n",
    "val volumefrom_max = statistics.getDouble(7)\n",
    "val volumefrom_range = volumefrom_max - volumefrom_min\n",
    "\n",
    "// // VolumeTo\n",
    "val volumeto_mean = statistics.getDouble(8)\n",
    "val volumeto_std = statistics.getDouble(9)\n",
    "val volumeto_min = statistics.getDouble(10)\n",
    "val volumeto_max = statistics.getDouble(11)\n",
    "val volumeto_range = volumeto_max - volumeto_min\n",
    "\n",
    "// // // from -1 to 1 \n",
    "// // //val new_dataset = dataset.withColumn(\"midPriceNorm\",($\"midPrice\" - midPrice_mean)/midPrice_std)\n",
    "// // // from 0 to 1 \n",
    "val new_dataset = dataset.withColumn(\"midPriceNorm\",(($\"midPrice\" - midPrice_min)/midPrice_range).cast(DoubleType))\n",
    "               .withColumn(\"volumefromNorm\",(($\"volumefrom\" - volumefrom_min)/volumefrom_range).cast(DoubleType))\n",
    "               .withColumn(\"volumetoNorm\",(($\"volumeto\" - volumeto_min)/volumeto_range).cast(DoubleType))\n",
    "               .cache()\n",
    "\n",
    "new_dataset.show(5)\n",
    "new_dataset.printSchema()\n",
    "\n",
    "println(\"All good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All good\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pre_processed_dataset = [time: int, high: double ... 12 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[time: int, high: double ... 12 more fields]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Saving data as Text\n",
    "\n",
    "// don't forget to delete the previous folder \n",
    "// RDD does not allow us to overwrite: https://community.cloudera.com/t5/Support-Questions/Apache-SPARK-Overwrite-data-file/m-p/105253\n",
    "val pre_processed_dataset = new_dataset.withColumn(\"empty\", typedLit(Seq(1)))\n",
    "pre_processed_dataset.rdd.repartition(1).saveAsTextFile(data_type)\n",
    "\n",
    "println(\"All good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
